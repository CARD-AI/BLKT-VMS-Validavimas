{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458749e5-e810-44e1-9df8-281c33b51c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hunspell\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize Hunspell\n",
    "hobj = hunspell.HunSpell(\n",
    "    \"../data/lt_dictionary/lt_LT.dic\", \"../data/lt_dictionary/lt_LT.aff\"\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b[\\wĄČĘĖĮŠŲŪŽąčęėįšųūž]+\\b\", text)\n",
    "\n",
    "\n",
    "def classify_words(text):\n",
    "    words = tokenize(text)\n",
    "    valid_words = [w for w in words if len(w) > 2 and w.isalpha()]\n",
    "\n",
    "    misspelled = []\n",
    "    # foreign = []\n",
    "\n",
    "    for word in valid_words:\n",
    "        if not hobj.spell(word):\n",
    "            suggestions = hobj.suggest(word)\n",
    "            if suggestions:\n",
    "                misspelled.append(word)  # probably a Lithuanian misspelling\n",
    "            # else:\n",
    "            #    foreign.append(word)     # likely a foreign word\n",
    "\n",
    "    total_words = len(valid_words)\n",
    "    return {\n",
    "        \"misspelled_words\": misspelled,\n",
    "        # \"foreign_words\": foreign,\n",
    "        \"misspelled_ratio\": len(misspelled) / total_words if total_words > 0 else 0.0,\n",
    "        # \"foreign_ratio\": len(foreign) / total_words if total_words > 0 else 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fbbcb93-6444-4283-ae77-d17077878942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 133386_lt.jsonl\n",
      "Processed 216087_lt.jsonl\n",
      "Processed 228262_lt.jsonl\n",
      "Processed 243341_lt.jsonl\n",
      "Processed 244056_lt.jsonl\n",
      "Processed 254781_lt.jsonl\n",
      "Processed 264516_lt.jsonl\n",
      "Processed 264898_lt.jsonl\n",
      "Processed 264939_lt.jsonl\n",
      "Processed 66624_lt.jsonl\n",
      "Processed 133386_lt-checkpoint.jsonl\n",
      "Processed 132839_lt.jsonl\n",
      "Processed 133868_lt.jsonl\n",
      "Processed 133885_lt.jsonl\n",
      "Processed 206292_lt.jsonl\n",
      "Processed 219163_lt.jsonl\n",
      "Processed 219207_lt.jsonl\n",
      "Processed 219410_lt.jsonl\n",
      "Processed 220609_lt.jsonl\n",
      "Processed 222403_lt.jsonl\n",
      "Processed 222829_lt.jsonl\n",
      "Processed 223729_lt.jsonl\n",
      "Processed 224632_lt.jsonl\n",
      "Processed 224772_lt.jsonl\n",
      "Processed 227242_lt.jsonl\n",
      "Processed 227877_lt.jsonl\n",
      "Processed 228216_lt.jsonl\n",
      "Processed 230481_lt.jsonl\n",
      "Processed 230565_lt.jsonl\n",
      "Processed 231187_lt.jsonl\n",
      "Processed 231801_lt.jsonl\n",
      "Processed 232365_lt.jsonl\n",
      "Processed 233946_lt.jsonl\n",
      "Processed 236364_lt.jsonl\n",
      "Processed 236373_lt.jsonl\n",
      "Processed 236422_lt.jsonl\n",
      "Processed 236903_lt.jsonl\n",
      "Processed 237009_lt.jsonl\n",
      "Processed 240051_lt.jsonl\n",
      "Processed 240452_lt.jsonl\n",
      "Processed 241143_lt.jsonl\n",
      "Processed 241325_lt.jsonl\n",
      "Processed 242740_lt.jsonl\n",
      "Processed 243516_lt.jsonl\n",
      "Processed 243782_lt.jsonl\n",
      "Processed 244052_lt.jsonl\n",
      "Processed 245184_lt.jsonl\n",
      "Processed 245563_lt.jsonl\n",
      "Processed 246265_lt.jsonl\n",
      "Processed 246643_lt.jsonl\n",
      "Processed 248092_lt.jsonl\n",
      "Processed 249371_lt.jsonl\n",
      "Processed 249628_lt.jsonl\n",
      "Processed 250679_lt.jsonl\n",
      "Processed 250746_lt.jsonl\n",
      "Processed 253710_lt.jsonl\n",
      "Processed 254450_lt.jsonl\n",
      "Processed 259843_lt.jsonl\n",
      "Processed 260370_lt.jsonl\n",
      "Processed 262421_lt.jsonl\n",
      "Processed 263955_lt.jsonl\n",
      "Processed 132839_lt-checkpoint.jsonl\n",
      "Processed 244052_lt-checkpoint.jsonl\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for file in Path(\"../data/\").rglob(\"*.jsonl\"):\n",
    "    try:\n",
    "        texts = []\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    if \"text\" in obj:\n",
    "                        texts.append(obj[\"text\"])\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping bad JSON in {file}\")\n",
    "\n",
    "        if not texts:\n",
    "            continue\n",
    "\n",
    "        combined_text = \" \".join(texts)\n",
    "        stats = classify_words(combined_text)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"dataset\": str(file.relative_to(\"../data/\")),\n",
    "                \"misspelled_ratio\": round(stats[\"misspelled_ratio\"], 4),\n",
    "                # \"foreign_ratio\": round(stats[\"foreign_ratio\"], 4),\n",
    "                \"misspelled_words\": sorted(set(stats[\"misspelled_words\"])),\n",
    "                # \"foreign_words\": sorted(set(stats[\"foreign_words\"]))\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Processed {file.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8016ca15-6748-4e52-a920-e83c67fec0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>misspelled_ratio</th>\n",
       "      <th>misspelled_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lt_test/133386_lt.jsonl</td>\n",
       "      <td>7.23</td>\n",
       "      <td>[Erik, Landesgericht, Taner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lt_test/216087_lt.jsonl</td>\n",
       "      <td>4.19</td>\n",
       "      <td>[Amministrativo, Antrepriză, Attuazione, BENJO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lt_test/228262_lt.jsonl</td>\n",
       "      <td>1.54</td>\n",
       "      <td>[AFI, Alimentos, Assche, BRF, Barrett, Bennett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lt_test/243341_lt.jsonl</td>\n",
       "      <td>2.06</td>\n",
       "      <td>[Anatomy, Anderson, Atlas, Campbell, Christof,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lt_test/244056_lt.jsonl</td>\n",
       "      <td>3.88</td>\n",
       "      <td>[Ampuero, Parker, Russell, SESV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>lt_train/254450_lt.jsonl</td>\n",
       "      <td>11.61</td>\n",
       "      <td>[Busch, EUIPO, European, Nestlé, Société, Vevė...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lt_train/259843_lt.jsonl</td>\n",
       "      <td>20.18</td>\n",
       "      <td>[Brien, Davis, EUIPO, Hofmann, Larsson, Messer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lt_train/260370_lt.jsonl</td>\n",
       "      <td>4.30</td>\n",
       "      <td>[Arslan, Luis, Santis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lt_train/262421_lt.jsonl</td>\n",
       "      <td>2.35</td>\n",
       "      <td>[ASVG, Acosta, Aliev, Alvin, Atkinson, BGBl, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>lt_train/263955_lt.jsonl</td>\n",
       "      <td>7.25</td>\n",
       "      <td>[Legero, Rieker, Schuh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dataset  misspelled_ratio  \\\n",
       "0    lt_test/133386_lt.jsonl              7.23   \n",
       "1    lt_test/216087_lt.jsonl              4.19   \n",
       "2    lt_test/228262_lt.jsonl              1.54   \n",
       "3    lt_test/243341_lt.jsonl              2.06   \n",
       "4    lt_test/244056_lt.jsonl              3.88   \n",
       "..                       ...               ...   \n",
       "56  lt_train/254450_lt.jsonl             11.61   \n",
       "57  lt_train/259843_lt.jsonl             20.18   \n",
       "58  lt_train/260370_lt.jsonl              4.30   \n",
       "59  lt_train/262421_lt.jsonl              2.35   \n",
       "60  lt_train/263955_lt.jsonl              7.25   \n",
       "\n",
       "                                     misspelled_words  \n",
       "0                        [Erik, Landesgericht, Taner]  \n",
       "1   [Amministrativo, Antrepriză, Attuazione, BENJO...  \n",
       "2   [AFI, Alimentos, Assche, BRF, Barrett, Bennett...  \n",
       "3   [Anatomy, Anderson, Atlas, Campbell, Christof,...  \n",
       "4                    [Ampuero, Parker, Russell, SESV]  \n",
       "..                                                ...  \n",
       "56  [Busch, EUIPO, European, Nestlé, Société, Vevė...  \n",
       "57  [Brien, Davis, EUIPO, Hofmann, Larsson, Messer...  \n",
       "58                             [Arslan, Luis, Santis]  \n",
       "59  [ASVG, Acosta, Aliev, Alvin, Atkinson, BGBl, B...  \n",
       "60                            [Legero, Rieker, Schuh]  \n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[\"misspelled_ratio\"] = result_df[\"misspelled_ratio\"] * 100\n",
    "result_df.iloc[:-2, :].to_csv(\n",
    "    \"../output/misspelled_proportion_of_words.csv\", index=False\n",
    ")\n",
    "result_df.iloc[:-2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23bd48c8-a6b5-442a-9e43-2180f01bcf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average non-Lithuanian word ratio (lt_test): 6.68%\n",
      "Average non-Lithuanian word ratio (lt_train): 7.68%\n"
     ]
    }
   ],
   "source": [
    "test_avg = result_df.iloc[:-2, :][\n",
    "    result_df.iloc[:-2, :][\"dataset\"].str.startswith(\"lt_test\")\n",
    "][\"misspelled_ratio\"].mean()\n",
    "train_avg = result_df.iloc[:-2, :][\n",
    "    result_df.iloc[:-2, :][\"dataset\"].str.startswith(\"lt_train\")\n",
    "][\"misspelled_ratio\"].mean()\n",
    "\n",
    "print(f\"Average non-Lithuanian word ratio (lt_test): {round(test_avg, 2)}%\")\n",
    "print(f\"Average non-Lithuanian word ratio (lt_train): {round(train_avg, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aff68e-2000-41f9-a6fb-28d6481bacfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
